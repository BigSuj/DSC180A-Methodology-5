Sujen Kancherla

skancherla@ucsd.edu


Section B13: Stochastic Optimization in Over-Parameterized Models: Neural Networks and Kernel Machines

Misha Belkin and Yian Ma


Questions:

1) The most interesting topic that we discussed was definitely the feature learning aspect of neural networks. It was very cool to see that neural networks are able to use only the important features in a prediction task even if they are given an inpout with many dimensions.

2) I think something I would like to investigate further in the quarter 2 project is to measure the performance of the nanoGPT project with a feature learning model before predicting with the nanoGPT trained model. Because we learned so much about the ability of neural networks to detect the most important features, I was wondering how the performance of this GPT model would look with a neural network doing the dimensionality reduction for less features, and the output was then used in the GPT prediction.

3) One change I would make to the current project is maybe adding more loss functions to test the performance on rather than only squared loss. I feel that we could mybe get a better statistical view of the performance with multiple loss functions that it is trained on rather than one.

4) I'm definietly excited to be working with the nanoGPT code that uses pytorch to train and implement the GPT model. It is very cool to see how the transformers models are implemented and seeing a basic version of how chatGPT runs.
